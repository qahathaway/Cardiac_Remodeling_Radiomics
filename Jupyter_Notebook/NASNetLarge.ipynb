{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create greyscale images###\n",
    "import os\n",
    "from os import path, rename\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "Output = '/media/john/My Passport1/Pyradiomics_Input_Output/Output/FullEcho/Grey_Full_Output/image/'\n",
    "\n",
    "for filename in os.listdir('/media/john/My Passport1/Pyradiomics_Input_Output/Output/FullEcho/IVS/'):\n",
    "    if filename.endswith('original_IVS.png'):\n",
    "        ##Open Mask File##\n",
    "        mask = Image.open(os.path.join('/media/john/My Passport1/Pyradiomics_Input_Output/Output/FullEcho/IVS', filename)).convert('L')\n",
    "        mask.save(path.join(Output, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Sort images into folders based on CSV###\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "from shutil import move\n",
    "import csv\n",
    "import os\n",
    "\n",
    "with open('/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full_Output/CHOICE_groundtruth.csv', newline='') as csvfile:\n",
    "    linereader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in linereader:\n",
    "        name = row[0]\n",
    "        label = row[1]\n",
    "        if label == 'o':\n",
    "            old_img_path = os.path.join(\"/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full_Output/image/\", name)\n",
    "            new_img_path = os.path.join(\"/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full/class1/\", name)\n",
    "            move(old_img_path, new_img_path)\n",
    "        if label == 'l':\n",
    "            old_img_path = os.path.join(\"/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full_Output/image/\", name)\n",
    "            new_img_path = os.path.join(\"/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full/class2/\", name)\n",
    "            move(old_img_path, new_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Random Splitting of folders into training/testing/validation###\n",
    "import splitfolders\n",
    "splitfolders.ratio('/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full/', output=\"/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full_Output/output/\", seed=100, ratio=(0.6, 0.2, 0.2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create masked image###\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from os import path, rename\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "Output = '/media/john/My Passport1/Pyradiomics_Input_Output/Output/Camp_India/Grey_PW/input/'\n",
    "\n",
    "for filename in os.listdir('/media/john/My Passport1/Pyradiomics_Input_Output/Output/Camp_India/Grey_Full/original_image/'):\n",
    "    if filename.endswith('original_IVS.png'):\n",
    "        ##Open Image File##\n",
    "        src1 = cv2.imread(os.path.join('/media/john/My Passport1/Pyradiomics_Input_Output/Output/Camp_India/Grey_Full/original_image/', filename)) \n",
    "    if filename.endswith('segmentation_PW.png'):\n",
    "        ##Open Mask File##\n",
    "        src1_mask = cv2.imread(os.path.join('/media/john/My Passport1/Pyradiomics_Input_Output/Output/Camp_India/Grey_Full/original_image/', filename))\n",
    "        mask_out=cv2.subtract(src1_mask,src1)\n",
    "        mask_out=cv2.subtract(src1_mask,mask_out)\n",
    "        differenceImage = Image.fromarray(mask_out)\n",
    "        differenceImage.save(path.join(Output, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from tensorflow.keras.preprocessing.image import image_dataset_from_directory\n",
    "from keras import  layers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "%autosave 5\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (331, 331)\n",
    "batch_size = 32\n",
    "input_shape=image_size + (3,)\n",
    "# number of output classes\n",
    "num_classes = 1\n",
    "\n",
    "class_names  =['class1','class2']\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/Users/quincy/Documents/Research/HVI/Radiomics - Automated/FINAL/DeepLearning/Grey_Full_Output_ASE-REWARD/output/train', \n",
    "    validation_split=0.2, subset='training',\n",
    "     seed=100,\n",
    "    image_size=image_size, batch_size=batch_size,\n",
    "    labels= \"inferred\",\n",
    "    class_names= class_names)\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/Users/quincy/Documents/Research/HVI/Radiomics - Automated/FINAL/DeepLearning/Grey_Full_Output_ASE-REWARD/output/val', validation_split=0.2, subset='validation', seed=100,\n",
    "    image_size=image_size, \n",
    "     labels= \"inferred\",\n",
    "     class_names= class_names,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(next(iter(val_ds.take(1))))\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/Users/quincy/Documents/Research/HVI/Radiomics - Automated/FINAL/DeepLearning/Grey_Full_Output_ASE-REWARD/output/test', seed=100,\n",
    "    image_size=image_size, \n",
    "     labels= \"inferred\",\n",
    "     class_names= class_names,\n",
    "     batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "#for images, labels in train_ds.take(1):\n",
    "for i, (images, labels) in enumerate(train_ds.take(9)):\n",
    "#  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    #plt.title(class_names[labels[i]])\n",
    "    plt.title(\"label  {n} : {s}\".format(n=labels[i].numpy(), s=class_names[labels[i]]),color='b')  \n",
    "    #plt.title(\"Label %s : %s\" % (labels[i].numpy(), class_names[labels[i]]))\n",
    "    plt.axis(\"off\")\n",
    "#    plt.savefig(\"/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full_Output/Labeled_Images.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import glob\n",
    "train_filenames = glob.glob('/Users/quincy/Documents/Research/HVI/Radiomics - Automated/FINAL/DeepLearning/Grey_Full_Output_ASE-REWARD/output/train/*/*')\n",
    "test_filenames = glob.glob('/Users/quincy/Documents/Research/HVI/Radiomics - Automated/FINAL/DeepLearning/Grey_Full_Output_ASE-REWARD/output/test/*/*')\n",
    "#filenames[0:5]\n",
    "rand_image = [train_filenames[i] for i in np.random.randint(len(train_filenames), size=10)]\n",
    "#rand_image = list(itertools.compress(filenames, np.random.randint(len(filenames), size=10)))\n",
    "#filenames[[0,1]]\n",
    "print(rand_image[0:2])\n",
    "print(len(train_filenames))\n",
    "print(len(test_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "for filename in train_filenames:\n",
    "   if \"class1\" in filename:\n",
    "      train_labels.append(\"class1\")\n",
    "   elif \"class2\" in filename:\n",
    "     train_labels.append(\"class2\")\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(train_labels).keys() )# equals to list(set(words))\n",
    "print(Counter(train_labels).values()) # counts the elements' frequency    \n",
    "print(Counter(train_labels)['class1'])\n",
    "print(Counter(train_labels)['class2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "for filename in test_filenames:\n",
    "   if \"class1\" in filename:\n",
    "      test_labels.append(\"class1\")\n",
    "   elif \"class2\" in filename:\n",
    "     test_labels.append(\"class2\")\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(test_labels).keys() )# equals to list(set(words))\n",
    "print(Counter(test_labels).values()) # counts the elements' frequency    \n",
    "print(Counter(test_labels)['class1'])\n",
    "print(Counter(test_labels)['class2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for filename in rand_image:\n",
    "   if \"class1\" in filename:\n",
    "      label.append(\"class1\")\n",
    "   elif \"class2\" in filename:\n",
    "     label.append(\"class2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "fig, axs = plt.subplots(2,5, figsize=(15, 6), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    axs[i].imshow(mpimg.imread(rand_image[i]))\n",
    "    axs[i].set_title(label[i])\n",
    "#plt.savefig(\"/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full_Output/Labeled_Images2.png\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation =tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomContrast(0.01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 10))\n",
    "#for images, _ in train_ds.take(1):\n",
    "for i, (images, _ ) in enumerate(train_ds.take(9)):\n",
    "  #for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype('uint8'))\n",
    "    plt.title(\"label  {n} : {s}\".format(n=_[0].numpy(), s=class_names[_[0]]),color='b') \n",
    "    plt.axis('off')\n",
    "#plt.savefig(\"/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full_Output/Labeled_Images3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    base_model = tf.keras.applications.NASNetLarge(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=input_shape,\n",
    "    include_top=False,\n",
    "     )\n",
    "\n",
    "# Freeze the base_model\n",
    "    base_model.trainable = False\n",
    "    optimizer=keras.optimizers.Adam(1e-3)\n",
    "\n",
    "# Create new model on top\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    norm_layer = tf.keras.layers.LayerNormalization(axis=1)\n",
    "    x = norm_layer(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = keras.layers.Dense(252, activation='relu')(x)\n",
    "    x = keras.layers.Dense(126, activation='sigmoid')(x)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "    outputs = tf.keras.layers.Dense(units=num_classes, activation = 'sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=METRICS)  #[keras.metrics.BinaryAccuracy()]\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.NASNetLarge(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=input_shape,\n",
    "    include_top=False,\n",
    "     )\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)\n",
    "# to_file='/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full_Output/Workflow.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "from PIL import ImageFont\n",
    "\n",
    "visualkeras.layered_view(model, legend=True).show() # display using your system viewer\n",
    "#visualkeras.layered_view(model, to_file='output.png') # write to disk\n",
    "#visualkeras.layered_view(model, legend=True, to_file='/Users/quincy/Documents/Research/HVI/Radiomics - Automated/FINAL/Submission/Nature Cardiovascular Research/Figures/NASNetLarge_output.png') # write and show\n",
    "\n",
    "#visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(train_labels)['class1'])\n",
    "print(Counter(train_labels)['class2'])\n",
    "\n",
    "\n",
    "initial_bias = np.log([Counter(train_labels)['class2']/Counter(train_labels)['class1']])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling by total/2 can keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / Counter(train_labels)['class1'])*(len(train_labels))/2.0 \n",
    "weight_for_1 = (1 / Counter(train_labels)['class2'])*(len(train_labels))/2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Include the epoch in the file name (uses `str.format`)\n",
    "#checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "#checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_p= \"/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full_Output/\"\n",
    "checkpoint_path = os.path.join(checkpoint_p, \"cp.ckpt\")\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_auc',\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_freq=10,\n",
    "                                                verbose=0 )\n",
    "\n",
    "# Keep only a single checkpoint, the best over test accuracy.\n",
    "#cp_callback  = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "#                            monitor='val_accuracy',\n",
    "#                            verbose=0,\n",
    "#                            save_best_only=True,\n",
    "#                            mode='max')\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "#verbose =2 print a lot of information\n",
    "early_stopping_monitor = tf.keras.callbacks.EarlyStopping(patience = 20 ,\n",
    "                                                          monitor = \"val_auc\", \n",
    "                                                        mode=\"max\",\n",
    "                                                          verbose = 0,\n",
    "                                                          restore_best_weights=True)\n",
    "# Train the model with the new callback\n",
    "history = model.fit(train_ds, \n",
    "          #train_labels,  \n",
    "          epochs=epochs,\n",
    "          class_weight=class_weight,\n",
    "           #steps_per_epoch= len(train_filenames)// batch_size, #run out of data\n",
    "          #validation_data=(test_images,test_labels),\n",
    "          validation_data=val_ds,\n",
    "          verbose=1,\n",
    "          callbacks=[cp_callback,early_stopping_monitor])  # Pass callback to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def plot_loss(history, label, n):\n",
    "  # Use a log scale to show the wide range of values.\n",
    "#  plt.plot(history.epoch,  history.history['loss'],\n",
    "#               color=colors[n], label='Train_loss '+label)\n",
    "#  plt.plot(history.epoch,  history.history['val_loss'],\n",
    " #         color=colors[n+1], label='Val_loss '+label,\n",
    " #         linestyle=\"--\")\n",
    " # plt.xlabel('Epoch')\n",
    " # plt.ylabel('Loss')\n",
    " # plt.legend()\n",
    "  #plt.savefig('acc.png')\n",
    "model.save('/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full_Output/normlayer_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 5, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['precision', 'recall', 'accuracy', 'loss','auc']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])\n",
    "\n",
    "\n",
    "plt.savefig(\"/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full_Output/Epochs1.png\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "  colors = plt.rcParams['axes.prop_cycle'].by_key()['color']  \n",
    "  #metrics =  ['loss', 'auc', 'precision', 'recall']\n",
    "  metrics =['precision', 'recall', 'accuracy', 'loss','auc']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(3,2,n+1)\n",
    "    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[1], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    #if metric == 'loss':\n",
    "    #  plt.ylim([0, plt.ylim()[1]])\n",
    "    #elif metric == 'auc':\n",
    "    #  plt.ylim([0.8,1])\n",
    "    #else:\n",
    "    #  plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history )\n",
    "plt.savefig(\"/media/john/My Passport1/Pyradiomics_Input_Output/Output/CHOICE/Grey_Full_Output/Epochs2.png\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the restored model on the valdatio set\n",
    "loss,tp,fp,tn,fn,accuracy,precision,recall,auc = model.evaluate(val_ds, verbose=2)\n",
    "print(' model accuracy: {:5.2f}%'.format(100*accuracy))\n",
    "print(' model Precision: {:5.2f}%'.format(100*precision))\n",
    "print(' model Recall: {:5.2f}%'.format(100*recall))\n",
    "print(' model True Positive: {:5.2f}'.format(tp))\n",
    "print(' model True Negative: {:5.2f}'.format(tn))\n",
    "print(' model False Positive: {:5.2f}'.format(fp))\n",
    "print(' model False Negative: {:5.2f}'.format(fn))\n",
    "print(' model loss: {:5.2f}'.format(loss))\n",
    "print(' model AUC: {:5.2f}%'.format(100*auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "#loss, acc = model.evaluate(val_ds, verbose=2)\n",
    "#print('Restored model, accuracy: {:5.2f}%'.format(100*acc))\n",
    "\n",
    "#print(new_model.predict(test_images).shape)\n",
    "\n",
    "predictions = model.predict(test_ds, batch_size=batch_size)\n",
    "\n",
    "\n",
    "test_labels_num =  [1 if x =='class2' else 0 for x in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "p=0.5\n",
    "\n",
    "def PlotConfusionMatrix(y_test,pred,y_test_normal,y_test_pneumonia,label):\n",
    "\n",
    "    cfn_matrix = confusion_matrix(y_test,pred)\n",
    "    cfn_norm_matrix = np.array([[1.0 / y_test_normal,1.0/y_test_normal],[1.0/y_test_pneumonia,1.0/y_test_pneumonia]])\n",
    "    norm_cfn_matrix = cfn_matrix * cfn_norm_matrix\n",
    "\n",
    "    #colsum=cfn_matrix.sum(axis=0)\n",
    "    #norm_cfn_matrix = cfn_matrix / np.vstack((colsum, colsum)).T\n",
    "\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    sns.heatmap(cfn_matrix,cmap='magma',linewidths=0.5,annot=True,ax=ax)\n",
    "    #tick_marks = np.arange(len(y_test))\n",
    "    #plt.xticks(tick_marks, np.unique(y_test), rotation=45)\n",
    "    plt.title('Confusion Matrix',color='b')\n",
    "    plt.ylabel('Real Classes')\n",
    "    plt.xlabel('Predicted Classes')\n",
    " #   plt.savefig('/content/drive/My Drive/Colab Notebooks/ComputerVision/cm_' +label +  '.png')\n",
    "        \n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    sns.heatmap(norm_cfn_matrix,cmap=plt.cm.Blues,linewidths=0.5,annot=True,ax=ax)\n",
    "\n",
    "    plt.title('Normalized Confusion Matrix',color='b')\n",
    "    plt.ylabel('Real Classes')\n",
    "    plt.xlabel('Predicted Classes')\n",
    "#    plt.savefig('/content/drive/My Drive/Colab Notebooks/ComputerVision/cm_norm' +label +  '.png')\n",
    "    plt.show()\n",
    "    \n",
    "    print('---Classification Report---')\n",
    "    print(classification_report(y_test,pred))\n",
    "    \n",
    "\n",
    "y_test_normal,y_test_pneumonia = np.bincount(test_labels_num)\n",
    "y_pred= np.where(predictions<p,0,1 )\n",
    "\n",
    "\n",
    "PlotConfusionMatrix(test_labels_num,y_pred,y_test_normal,y_test_pneumonia,label='classification')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss, acc, prec, rec = model.evaluate(test_ds)\n",
    "\n",
    "# Evaluate the restored model on the test set\n",
    "loss,tp,fp,tn,fn,accuracy,precision,recall,auc =  model.evaluate(test_ds, verbose=2)\n",
    "print(' model accuracy: {:5.2f}%'.format(100*accuracy))\n",
    "print(' model Precision: {:5.2f}%'.format(100*precision))\n",
    "print(' model Recall: {:5.2f}%'.format(100*recall))\n",
    "print(' model True Positive: {:5.2f}'.format(tp))\n",
    "print(' model True Negative: {:5.2f}'.format(tn))\n",
    "print(' model False Positive: {:5.2f}'.format(fp))\n",
    "print(' model False Negative: {:5.2f}'.format(fn))\n",
    "print(' model loss: {:5.2f}'.format(loss))\n",
    "print(' model AUC: {:5.2f}%'.format(100*auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
