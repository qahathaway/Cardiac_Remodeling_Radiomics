{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create greyscale images###\n",
    "import os\n",
    "from os import path, rename\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "Output = '/path/to/directory/'\n",
    "\n",
    "for filename in os.listdir('/path/to/directory/'):\n",
    "    if filename.endswith('original_IVS.png'):\n",
    "        ##Open Mask File##\n",
    "        mask = Image.open(os.path.join('/path/to/directory/', filename)).convert('L')\n",
    "        mask.save(path.join(Output, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Sort images into folders based on CSV###\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "from shutil import move\n",
    "import csv\n",
    "import os\n",
    "\n",
    "with open('/path/to/file.csv', newline='') as csvfile:\n",
    "    linereader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in linereader:\n",
    "        name = row[0]\n",
    "        label = row[1]\n",
    "        if label == 'o':\n",
    "            old_img_path = os.path.join(\"/path/to/directory/\", name)\n",
    "            new_img_path = os.path.join(\"/path/to/directory/\", name)\n",
    "            move(old_img_path, new_img_path)\n",
    "        if label == 'l':\n",
    "            old_img_path = os.path.join(\"/path/to/directory/\", name)\n",
    "            new_img_path = os.path.join(\"/path/to/directory/\", name)\n",
    "            move(old_img_path, new_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create masked image###\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from os import path, rename\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "Output = '/path/to/directory/'\n",
    "\n",
    "for filename in os.listdir('/path/to/directory/'):\n",
    "    if filename.endswith('original_IVS.png'):\n",
    "        ##Open Image File##\n",
    "        src1 = cv2.imread(os.path.join('/path/to/directory/', filename)) \n",
    "    if filename.endswith('segmentation_IVS.png'):\n",
    "        ##Open Mask File##\n",
    "        src1_mask = cv2.imread(os.path.join('/path/to/directory/', filename))\n",
    "        mask_out=cv2.subtract(src1_mask,src1)\n",
    "        mask_out=cv2.subtract(src1_mask,mask_out)\n",
    "        differenceImage = Image.fromarray(mask_out)\n",
    "        differenceImage.save(path.join(Output, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from tensorflow.keras.preprocessing.image import image_dataset_from_directory\n",
    "from keras import  layers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "%autosave 5\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (331, 331)\n",
    "batch_size = 32\n",
    "input_shape=image_size + (3,)\n",
    "# number of output classes\n",
    "num_classes = 1\n",
    "\n",
    "class_names  =['class1','class2']\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/path/to/directory', \n",
    "    validation_split=0.2, subset='training',\n",
    "     seed=100,\n",
    "    image_size=image_size, batch_size=batch_size,\n",
    "    labels= \"inferred\",\n",
    "    class_names= class_names)\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/path/to/directory', validation_split=0.2, subset='validation', seed=100,\n",
    "    image_size=image_size, \n",
    "     labels= \"inferred\",\n",
    "     class_names= class_names,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(next(iter(val_ds.take(1))))\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '/path/to/directory', seed=100,\n",
    "    image_size=image_size, \n",
    "     labels= \"inferred\",\n",
    "     class_names= class_names,\n",
    "     batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "#for images, labels in train_ds.take(1):\n",
    "for i, (images, labels) in enumerate(train_ds.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(\"label  {n} : {s}\".format(n=labels[i].numpy(), s=class_names[labels[i]]),color='b')  \n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import glob\n",
    "train_filenames = glob.glob('/path/to/directory/*/*')\n",
    "test_filenames = glob.glob('/path/to/directory/*/*')\n",
    "rand_image = [train_filenames[i] for i in np.random.randint(len(train_filenames), size=10)]\n",
    "print(rand_image[0:2])\n",
    "print(len(train_filenames))\n",
    "print(len(test_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "for filename in train_filenames:\n",
    "   if \"class1\" in filename:\n",
    "      train_labels.append(\"class1\")\n",
    "   elif \"class2\" in filename:\n",
    "     train_labels.append(\"class2\")\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(train_labels).keys() )# equals to list(set(words))\n",
    "print(Counter(train_labels).values()) # counts the elements' frequency    \n",
    "print(Counter(train_labels)['class1'])\n",
    "print(Counter(train_labels)['class2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "for filename in test_filenames:\n",
    "   if \"class1\" in filename:\n",
    "      test_labels.append(\"class1\")\n",
    "   elif \"class2\" in filename:\n",
    "     test_labels.append(\"class2\")\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(test_labels).keys() )# equals to list(set(words))\n",
    "print(Counter(test_labels).values()) # counts the elements' frequency    \n",
    "print(Counter(test_labels)['class1'])\n",
    "print(Counter(test_labels)['class2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for filename in rand_image:\n",
    "   if \"class1\" in filename:\n",
    "      label.append(\"class1\")\n",
    "   elif \"class2\" in filename:\n",
    "     label.append(\"class2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "fig, axs = plt.subplots(2,5, figsize=(15, 6), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    axs[i].imshow(mpimg.imread(rand_image[i]))\n",
    "    axs[i].set_title(label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation =tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomContrast(0.01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 10))\n",
    "#for images, _ in train_ds.take(1):\n",
    "for i, (images, _ ) in enumerate(train_ds.take(9)):\n",
    "  #for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype('uint8'))\n",
    "    plt.title(\"label  {n} : {s}\".format(n=_[0].numpy(), s=class_names[_[0]]),color='b') \n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    base_model = tf.keras.applications.NASNetLarge(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=input_shape,\n",
    "    include_top=False,\n",
    "     )\n",
    "\n",
    "# Freeze the base_model\n",
    "    base_model.trainable = False\n",
    "    optimizer=keras.optimizers.Adam(1e-3)\n",
    "\n",
    "# Create new model on top\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    norm_layer = tf.keras.layers.LayerNormalization(axis=1)\n",
    "    x = norm_layer(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = keras.layers.Dense(252, activation='relu')(x)\n",
    "    x = keras.layers.Dense(126, activation='sigmoid')(x)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "    outputs = tf.keras.layers.Dense(units=num_classes, activation = 'sigmoid')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=METRICS)  #[keras.metrics.BinaryAccuracy()]\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.NASNetLarge(\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=input_shape,\n",
    "    include_top=False,\n",
    "     )\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "from PIL import ImageFont\n",
    "\n",
    "visualkeras.layered_view(model, legend=True).show() # display using your system viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(train_labels)['class1'])\n",
    "print(Counter(train_labels)['class2'])\n",
    "\n",
    "\n",
    "initial_bias = np.log([Counter(train_labels)['class2']/Counter(train_labels)['class1']])\n",
    "initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling by total/2 can keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / Counter(train_labels)['class1'])*(len(train_labels))/2.0 \n",
    "weight_for_1 = (1 / Counter(train_labels)['class2'])*(len(train_labels))/2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_p= \"/path/to/directory/\"\n",
    "checkpoint_path = os.path.join(checkpoint_p, \"cp.ckpt\")\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_auc',\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_freq=10,\n",
    "                                                 verbose=0 )\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "#verbose =2 print a lot of information\n",
    "early_stopping_monitor = tf.keras.callbacks.EarlyStopping(patience = 20 ,\n",
    "                                                          monitor = \"val_auc\", \n",
    "                                                          mode=\"max\",\n",
    "                                                          verbose = 0,\n",
    "                                                          restore_best_weights=True)\n",
    "# Train the model with the new callback\n",
    "history = model.fit(train_ds, \n",
    "          #train_labels,  \n",
    "          epochs=epochs,\n",
    "          class_weight=class_weight,\n",
    "          validation_data=val_ds,\n",
    "          verbose=1,\n",
    "          callbacks=[cp_callback,early_stopping_monitor])  # Pass callback to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 5, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['precision', 'recall', 'accuracy', 'loss','auc']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].plot(history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "  colors = plt.rcParams['axes.prop_cycle'].by_key()['color']  \n",
    "  #metrics =  ['loss', 'auc', 'precision', 'recall']\n",
    "  metrics =['precision', 'recall', 'accuracy', 'loss','auc']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(3,2,n+1)\n",
    "    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[1], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the restored model on the valdation set\n",
    "loss,tp,fp,tn,fn,accuracy,precision,recall,auc = model.evaluate(val_ds, verbose=2)\n",
    "print(' model accuracy: {:5.2f}%'.format(100*accuracy))\n",
    "print(' model Precision: {:5.2f}%'.format(100*precision))\n",
    "print(' model Recall: {:5.2f}%'.format(100*recall))\n",
    "print(' model True Positive: {:5.2f}'.format(tp))\n",
    "print(' model True Negative: {:5.2f}'.format(tn))\n",
    "print(' model False Positive: {:5.2f}'.format(fp))\n",
    "print(' model False Negative: {:5.2f}'.format(fn))\n",
    "print(' model loss: {:5.2f}'.format(loss))\n",
    "print(' model AUC: {:5.2f}%'.format(100*auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss, acc, prec, rec = model.evaluate(test_ds)\n",
    "\n",
    "# Evaluate the restored model on the test set\n",
    "loss,tp,fp,tn,fn,accuracy,precision,recall,auc =  model.evaluate(test_ds, verbose=2)\n",
    "print(' model accuracy: {:5.2f}%'.format(100*accuracy))\n",
    "print(' model Precision: {:5.2f}%'.format(100*precision))\n",
    "print(' model Recall: {:5.2f}%'.format(100*recall))\n",
    "print(' model True Positive: {:5.2f}'.format(tp))\n",
    "print(' model True Negative: {:5.2f}'.format(tn))\n",
    "print(' model False Positive: {:5.2f}'.format(fp))\n",
    "print(' model False Negative: {:5.2f}'.format(fn))\n",
    "print(' model loss: {:5.2f}'.format(loss))\n",
    "print(' model AUC: {:5.2f}%'.format(100*auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
